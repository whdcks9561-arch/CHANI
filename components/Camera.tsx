"use client";

import { useRef, useState, useEffect } from "react";
import { analyzeFace } from "../services/geminiService";

export default function Camera() {
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);

  const [stream, setStream] = useState<MediaStream | null>(null);
  const [isCameraOn, setIsCameraOn] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [result, setResult] = useState<string | null>(null);

  /* =========================
     ğŸ“¸ ì¹´ë©”ë¼ ì‹œì‘ (ë²„íŠ¼ í´ë¦­)
     ========================= */
  const startCamera = async () => {
    try {
      if (!navigator.mediaDevices?.getUserMedia) {
        alert("ì´ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }

      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "user",
          width: { ideal: 1280 },
          height: { ideal: 720 },
        },
        audio: false,
      });

      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
        videoRef.current.muted = true; // iOS í•„ìˆ˜
        await videoRef.current.play();
      }

      setStream(mediaStream);
      setIsCameraOn(true);
      setResult(null); // ìƒˆ ì´¬ì˜ ì‹œ ì´ì „ ê²°ê³¼ ì´ˆê¸°í™”
    } catch (error) {
      console.error("ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜:", error);
      alert("ì¹´ë©”ë¼ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\në¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }
  };

  /* =========================
     ğŸ§¯ ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì¹´ë©”ë¼ ì¢…ë£Œ
     ========================= */
  useEffect(() => {
    return () => {
      if (stream) {
        stream.getTracks().forEach((track) => track.stop());
      }
    };
  }, [stream]);

  /* =========================
     ğŸ“· ì‚¬ì§„ ì´¬ì˜ + ê´€ìƒ ë¶„ì„
     ========================= */
  const capturePhoto = async () => {
    if (!videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const imageData = canvas.toDataURL("image/png");

    setIsAnalyzing(true);
    setResult(null);

    try {
      const analysis = await analyzeFace(imageData);
      setResult(analysis);
    } catch (error) {
      console.error(error);
      setResult("ê´€ìƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
    } finally {
      setIsAnalyzing(false);
    }
  };

  return (
    <div className="flex flex-col items-center gap-6 w-full max-w-md mx-auto p-4">
      {!isCameraOn && (
        <button
          onClick={startCamera}
          className="px-6 py-3 bg-amber-500 text-black font-bold rounded-full"
        >
          ğŸ“¸ ì´¬ì˜ ì‹œì‘
        </button>
      )}

      <div className="w-full aspect-[3/4] bg-black rounded-xl overflow-hidden">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          className="w-full h-full object-cover"
        />
      </div>

      {isCameraOn && !isAnalyzing && (
        <button
          onClick={capturePhoto}
          className="px-6 py-3 bg-blue-600 text-white font-bold rounded-full"
        >
          ğŸ“· ì‚¬ì§„ ì´¬ì˜
        </button>
      )}

      {isAnalyzing && (
        <p className="text-sm text-slate-400 mt-2">
          ğŸ”® ê´€ìƒ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...
        </p>
      )}

      {result && (
        <div className="mt-4 p-4 bg-slate-800 rounded-xl text-sm whitespace-pre-line">
          {result}
        </div>
      )}

      <canvas ref={canvasRef} className="hidden" />
    </div>
  );
}
